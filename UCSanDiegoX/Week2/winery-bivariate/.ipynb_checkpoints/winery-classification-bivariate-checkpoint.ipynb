{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the bivariate Gaussian\n",
    "\n",
    "Our first generative model for Winery classification used just one feature. Now we use two features, modeling each class by a **bivariate Gaussian**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the univariate case, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal \n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of two features from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to plot the distribution of two features from a particular winery. We will use several helper functions for this. It is worth understanding each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first helper function fits a Gaussian to a data set, restricting attention to specified features.\n",
    "It returns the mean and covariance matrix of the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a Gaussian to a data set using the selected features\n",
    "def fit_gaussian(x, features):\n",
    "    mu = np.mean(x[:,features], axis=0)\n",
    "    covar = np.cov(x[:,features], rowvar=0, bias=1)\n",
    "    return mu, covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's look at the Gaussian we get for winery 1, using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "[ 13.78534884   2.99627907]\n",
      "Covariance matrix:\n",
      "[[ 0.23325279  0.07526874]\n",
      " [ 0.07526874  0.15240941]]\n"
     ]
    }
   ],
   "source": [
    "f1 = 0\n",
    "f2 = 6\n",
    "label = 1\n",
    "mu, covar = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "print (\"Mean:\\n\" + str(mu))\n",
    "print (\"Covariance matrix:\\n\" + str(covar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct a routine for displaying points sampled from a two-dimensional Gaussian, as well as a few contour lines. Part of doing this involves deciding what range to use for each axis. We begin with a little helper function that takes as input an array of numbers (values along a single feature) and returns the range in which these numbers lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the range within which an array of numbers lie, with a little buffer\n",
    "def find_range(x):\n",
    "    lower = min(x)\n",
    "    upper = max(x)\n",
    "    width = upper - lower\n",
    "    lower = lower - 0.2 * width\n",
    "    upper = upper + 0.2 * width\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a routine that plots a few contour lines of a given two-dimensional Gaussian.\n",
    "It takes as input:\n",
    "* `mu`, `cov`: the parameters of the Gaussian\n",
    "* `x1g`, `x2g`: the grid (along the two axes) at which the density is to be computed\n",
    "* `col`: the color of the contour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_contours(mu, cov, x1g, x2g, col):\n",
    "    rv = multivariate_normal(mean=mu, cov=cov)\n",
    "    z = np.zeros((len(x1g),len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            z[j,i] = rv.logpdf([x1g[i], x2g[j]]) \n",
    "    sign, logdet = np.linalg.slogdet(cov)\n",
    "    normalizer = -0.5 * (2 * np.log(6.28) + sign * logdet)\n",
    "    for offset in range(1,4):\n",
    "        plt.contour(x1g,x2g,z, levels=[normalizer - offset], colors=col, linewidths=2.0, linestyles='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **two_features_plot** takes an input two features and a label, and displays the distribution for the specified winery and pair of features.\n",
    "\n",
    "The first line allows you to specify the parameters interactively using sliders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287db3d1b539405487a50106514203c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1), label=IntSlider(1,1,3,1) )\n",
    "def two_features_plot(f1,f2,label):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print (\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[trainy==label,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[trainy==label,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    plt.plot(trainx[trainy==label, f1], trainx[trainy==label, f2], 'ro')\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Now plot a few contour lines of the density\n",
    "    mu, cov = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "    plot_contours(mu, cov, x1g, x2g, 'k')\n",
    "    \n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Class ' + str(label), fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that will fit a Gaussian generative model to the three classes, restricted to a given list of features. The function returns:\n",
    "* `mu`: the means of the Gaussians, one per row\n",
    "* `covar`: covariance matrices of each of the Gaussians\n",
    "* `pi`: list of three class weights summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(x, y, features):\n",
    "    k = 3 # number of classes\n",
    "    d = len(features) # number of features\n",
    "    mu = np.zeros((k+1,d)) # list of means\n",
    "    covar = np.zeros((k+1,d,d)) # list of covariance matrices\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label,:], covar[label,:,:] = fit_gaussian(x[indices,:], features)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, covar, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the three Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f3195ba1a547b0bb800fdb26cc46d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def three_class_plot(f1,f2):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print (\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Show the Gaussian fit to each class, using features f1,f2\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    for label in range(1,4):\n",
    "        gmean = mu[label,:]\n",
    "        gcov = covar[label,:,:]\n",
    "        plot_contours(gmean, gcov, x1g, x2g, colors[label-1])\n",
    "\n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Wine data', fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we can predict the class (1,2,3) based just on these two features?\n",
    "\n",
    "We start with a testing procedure that is analogous to what we developed in the 1-d case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e57ed1a81847f5b7fe3bf1b428671a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "@interact( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def test_model(f1, f2):\n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print (\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    features= [f1,f2]\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, features)\n",
    "    \n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    nt = len(testy) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            multivariate_normal.logpdf(testx[i,features], mean=mu[label,:], cov=covar[label,:,:])\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print (\"Test error using feature(s): \"),\n",
    "    for f in features:\n",
    "        print (\"'\" + featurenames[f] + \"'\" + \" \"),\n",
    "    print\n",
    "    print (\"Errors: \" + str(errors) + \"/\" + str(nt))# Now test the performance of a predictor based on a subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different pairs of features yield different test errors.\n",
    "* What is the smallest achievable test error?\n",
    "* Which pair of features achieves this minimum test error?\n",
    "\n",
    "*Make a note of your answers to these questions, as you will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min error:  3.0\n",
      "features:  [6, 9]\n"
     ]
    }
   ],
   "source": [
    "def test_model(f1, f2):\n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print (\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    features= [f1,f2]\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, features)\n",
    "    \n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    nt = len(testy) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            multivariate_normal.logpdf(testx[i,features], mean=mu[label,:], cov=covar[label,:,:])\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    return errors\n",
    "\n",
    "features = {}\n",
    "errors = np.zeros(12*13)\n",
    "counter = 0\n",
    "\n",
    "for f1 in range(0,13):\n",
    "    for f2 in range(0,13):\n",
    "        if f1 != f2:\n",
    "            features[counter] = [f1, f2]\n",
    "            errors[counter] = test_model(f1, f2)\n",
    "            counter += 1\n",
    "\n",
    "print('min error: ', np.min(errors))\n",
    "print('features: ', features[np.argmin(errors)])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. The decision boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **show_decision_boundary** takes as input two features, builds a classifier based only on these two features, and shows a plot that contains both the training data and the decision boundary.\n",
    "\n",
    "To compute the decision boundary, a dense grid is defined on the two-dimensional input space and the classifier is applied to every grid point. The built-in `pyplot.contour` function can then be invoked to depict the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4b8ad32a4b41f7993f8e2ed9956056"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function above to draw the decision boundary using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEOCAYAAACAfcAXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFIqQWkCUEqpBPX/Aa6QtNXNLutHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112085a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_decision_boundary(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you add interactive sliders to function **show_decision_boundary**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a plot similar to that of **show_decision_boundary**, but in which just the **test** data is shown.\n",
    "Look back at your answer to *Fast exercise 1*. Is it corroborated by your plot? Are the errors clearly visible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd81c7a369749daa5b834afceac8a42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(testx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(testx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(testx[testy==label,f1], testx[testy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
